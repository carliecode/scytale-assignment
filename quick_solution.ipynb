{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b3f103-ada8-4a45-bca8-89f15315c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import *\n",
    "from pyspark.sql import SparkSession,functions as F\n",
    "from pyspark.sql.types import IntegerType, StringType, StructType, StructField, TimestampType\n",
    "from pyspark.sql.functions import col, concat_ws, split\n",
    "from github import Github\n",
    "import json,os, datetime\n",
    "\n",
    "\n",
    "\n",
    "# read configuration from config file\n",
    "configs = project_configs\n",
    "github_token = configs[\"token\"]\n",
    "org_name = configs[\"org_name\"]\n",
    "#spark_master = configs[\"spark_master\"]\n",
    "\n",
    "#\n",
    "#\n",
    "# create PyGithub client with authentication token\n",
    "gh = Github(github_token)\n",
    "files_path = os.getcwd() +  r'/extracted_json_files/' \n",
    "repos = gh.get_organization(org_name).get_repos()\n",
    "\n",
    "for repo in repos:\n",
    "    pr_filename = files_path + repo.name + \".json\"\n",
    "    list_prs = []\n",
    "    for pr in repo.get_pulls(state='all'):\n",
    "        pr_data = {\n",
    "            'organization_name' : repo.full_name,\n",
    "            'repository_id' : repo.id,\n",
    "            'repository_name' : repo.name,\n",
    "            'repository_owner' : repo.owner.login,\n",
    "            'merged_at' : str(pr.merged_at),\n",
    "            'state' : pr.state\n",
    "            }\n",
    "        list_prs.append(pr_data)\n",
    "        with open(pr_filename, 'w') as f:\n",
    "            json.dump(list_prs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9efa3e5d-fdb9-4e4d-b834-1c5f1c664fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsMetaData = StructType(\n",
    "    [StructField(\"organization_name\", StringType(), True),\n",
    "     StructField(\"repository_id\", StringType(), True),\n",
    "     StructField(\"repository_name\", StringType(), True),\n",
    "     StructField(\"repository_owner\", StringType(), True),\n",
    "     #StructField(\"title\", StringType(), True),\n",
    "     StructField(\"merged_at\", TimestampType(), True),\n",
    "     StructField(\"state\", StringType(), True)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6caddc0-37a1-4bef-999f-873211bae1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+----------------+-------------------+------+\n",
      "|organization_name|repository_id|repository_name|repository_owner|          merged_at| state|\n",
      "+-----------------+-------------+---------------+----------------+-------------------+------+\n",
      "| Scytale-exercise|    721612130|  scytale-repo3|Scytale-exercise|2023-11-21 12:29:07|closed|\n",
      "| Scytale-exercise|    721612130|  scytale-repo3|Scytale-exercise|2023-11-21 12:27:11|closed|\n",
      "| Scytale-exercise|    721612130|  scytale-repo3|Scytale-exercise|2023-11-21 12:25:14|closed|\n",
      "| Scytale-exercise|    721612130|  scytale-repo3|Scytale-exercise|2023-11-21 12:23:48|closed|\n",
      "| Scytale-exercise|    724133322|   Scytale_repo|Scytale-exercise|               NULL|  open|\n",
      "| Scytale-exercise|    724133322|   Scytale_repo|Scytale-exercise|               NULL|closed|\n",
      "| Scytale-exercise|    724140378|  scytale-repo2|Scytale-exercise|2023-11-27 13:34:05|closed|\n",
      "+-----------------+-------------+---------------+----------------+-------------------+------+\n",
      "\n",
      "+-----------------+-------------+----------------+-------+\n",
      "|organization_name|repository_id|repository_owner|num_prs|\n",
      "+-----------------+-------------+----------------+-------+\n",
      "| Scytale-exercise|    721612130|Scytale-exercise|      4|\n",
      "| Scytale-exercise|    724133322|Scytale-exercise|      2|\n",
      "| Scytale-exercise|    724140378|Scytale-exercise|      1|\n",
      "+-----------------+-------------+----------------+-------+\n",
      "\n",
      "+-------------+--------------+\n",
      "|repository_id|num_prs_merged|\n",
      "+-------------+--------------+\n",
      "|    721612130|             4|\n",
      "|    724140378|             1|\n",
      "+-------------+--------------+\n",
      "\n",
      "+-------------+-------------------+\n",
      "|repository_id|          merged_at|\n",
      "+-------------+-------------------+\n",
      "|    721612130|2023-11-21 12:29:07|\n",
      "|    724133322|               NULL|\n",
      "|    724140378|2023-11-27 13:34:05|\n",
      "+-------------+-------------------+\n",
      "\n",
      "+-----------------+-------------+----------------+-------+--------------+-------------------+------------+\n",
      "|organization_name|repository_id|repository_owner|num_prs|num_prs_merged|          merged_at|is_compliant|\n",
      "+-----------------+-------------+----------------+-------+--------------+-------------------+------------+\n",
      "| Scytale-exercise|    721612130|Scytale-exercise|      4|             4|2023-11-21 12:29:07|           0|\n",
      "| Scytale-exercise|    724133322|Scytale-exercise|      2|          NULL|               NULL|           0|\n",
      "| Scytale-exercise|    724140378|Scytale-exercise|      1|             1|2023-11-27 13:34:05|           0|\n",
      "+-----------------+-------------+----------------+-------+--------------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load files into sparksession\n",
    "spark = SparkSession.builder.appName(\"GithubPRsToParquet\").getOrCreate()\n",
    "df=spark.read.json(files_path, columnsMetaData)\n",
    "\n",
    "#cleaning the data and transforming the datasets\n",
    "df = df.withColumn('organization_name',split(col('organization_name'),'/')[0])\n",
    "\n",
    "df_num_prs = df.groupBy('organization_name','repository_id','repository_owner') \\\n",
    "    .count().withColumnRenamed('count', 'num_prs') \n",
    "\n",
    "df_num_merged_prs = df.filter(col('merged_at').isNotNull())\n",
    "df_num_merged_prs = df_num_merged_prs.groupBy('repository_id') \\\n",
    "   .count().withColumnRenamed('count', \"num_prs_merged\")\n",
    "\n",
    "df_merged_at = df.groupBy('repository_id') \\\n",
    "    .agg(F.max('merged_at').alias('merged_at'))\n",
    "\n",
    "df.show()\n",
    "df_num_prs.show()\n",
    "df_num_merged_prs.show()\n",
    "df_merged_at.show()\n",
    "\n",
    "df = df_num_prs.join(df_num_merged_prs, ['repository_id'], how='left') \\\n",
    "     .join(df_merged_at, df_num_prs['repository_id'] == df_merged_at['repository_id'], how='left') \\\n",
    "     .select('organization_name',df_num_prs['repository_id'],'repository_owner','num_prs','num_prs_merged', 'merged_at')\n",
    "\n",
    "df = df.withColumn(\n",
    "    'is_compliant',\n",
    "    F.when((F.col(\"num_prs\") == F.col(\"num_prs_merged\")) & F.col(\"repository_owner\").like('%scytale%') , 1)\\\n",
    "    .otherwise(0)\n",
    ")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5459d8-1c0a-4072-bc95-60d51e96af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').format('parquet').save(files_path + 'ouput_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba92d3-b1d4-4733-98aa-c19d2476f3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
